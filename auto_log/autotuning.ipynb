{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "import topi\n",
    "import torch\n",
    "from tvm import autotvm\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from fast3d.autotuning import auto_tune, the_best_config_model\n",
    "from fast3d.get_data import *\n",
    "from fast3d.schedules import schedule_direct_3d_cuda, schedule_conv3d_transpose_nchw_cuda, schedule_conv3d_nchw_cuda\n",
    "from fast3d.utils import _grad_input_padding,return_log_name,reshape_inp_weight_shape, conv3d_ZHW_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use it\n",
    "You can define a data_dict which contain the conv layer information you want to autotune.\n",
    "\n",
    "After autotuning, you can copy the log file to \"auto_log\" folder.\n",
    "\n",
    "Remeber change the config.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "             0:{\n",
    "                      \"inshape\":(1, 1, 64, 128, 128),\n",
    "                      \"kershape\":(24, 1, 1, 5, 5),\n",
    "                      \"outshape\":(1, 24, 64, 64, 64),\n",
    "                      \"stride\":(1, 2, 2),\n",
    "                      \"padding\":(0, 2, 2),\n",
    "                      \"dilation\":1,\n",
    "                      \"groups\":1,\n",
    "                      \"bias\": None\n",
    "                     },\n",
    "    \n",
    "             1:{\n",
    "                      \"inshape\":(1, 24, 64, 128, 128),\n",
    "                      \"kershape\":(12, 24, 1, 1, 1),\n",
    "                      \"outshape\":(1, 12, 64, 128, 128),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(0, 0, 0),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },\n",
    "    \n",
    "            2:{\n",
    "                      \"inshape\":(1, 32, 64, 128, 128),\n",
    "                      \"kershape\":(12, 32,1, 1, 1),\n",
    "                      \"outshape\":(1, 12, 64, 128, 128),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(0, 0, 0),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },\n",
    "            3:{\n",
    "                      \"inshape\":(1, 24, 64, 64, 64),\n",
    "                      \"kershape\":(24, 24, 3, 3, 3),\n",
    "                      \"outshape\":(1, 24, 64, 64, 64),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(1, 1, 1),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },  \n",
    "            4:{\n",
    "                      \"inshape\":(1, 64, 32, 32, 32),\n",
    "                      \"kershape\":(64,64,3,3,3),\n",
    "                      \"outshape\":(1, 64, 32, 32, 32),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(1, 1, 1),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },\n",
    "            5:{\n",
    "                      \"inshape\":(1, 192, 16, 16, 16),\n",
    "                      \"kershape\":(192,192,3,3,3),\n",
    "                      \"outshape\":(1, 192, 16, 16, 16),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(1, 1, 1),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },\n",
    "            6:{\n",
    "                      \"inshape\":(1, 192, 8, 8, 8),\n",
    "                      \"kershape\":(192,192, 3, 3, 3),\n",
    "                      \"outshape\":(1, 192, 8, 8, 8),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(1, 1, 1),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },\n",
    "            7:{\n",
    "                      \"inshape\":(1, 384, 8, 8, 8),\n",
    "                      \"kershape\":(384, 384, 3, 3, 3),\n",
    "                      \"outshape\":(1, 384, 8, 8, 8),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(1, 1, 1),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },\n",
    "            8:{\n",
    "                      \"inshape\":(1, 24, 32, 32, 32),\n",
    "                      \"kershape\":(64, 24, 1, 1, 1),\n",
    "                      \"outshape\":(1, 64, 32, 32, 32),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(0, 0, 0),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },\n",
    "            9:{\n",
    "                      \"inshape\":(1, 64, 32, 32, 32),\n",
    "                      \"kershape\":(24, 64, 1, 1, 1),\n",
    "                      \"outshape\":(1, 24, 32, 32, 32),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(0, 0, 0),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },\n",
    "            10:{\n",
    "                      \"inshape\":(1, 64, 16, 16, 16),\n",
    "                      \"kershape\":(192, 64, 1, 1, 1),\n",
    "                      \"outshape\":(1, 192, 16, 16, 16),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(0, 0, 0),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },   \n",
    "            11:{\n",
    "                      \"inshape\":(1, 192, 16, 16, 16),\n",
    "                      \"kershape\":(64, 192, 1, 1, 1),\n",
    "                      \"outshape\":(1, 64, 16, 16, 16),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(0, 0, 0),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },    \n",
    "            12:{\n",
    "                      \"inshape\":(1, 192, 8, 8, 8),\n",
    "                      \"kershape\":(384, 192, 1, 1, 1),\n",
    "                      \"outshape\":(1, 384, 8, 8, 8),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(0, 0, 0),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },        \n",
    "            13:{\n",
    "                      \"inshape\":(1, 384, 8, 8, 8),\n",
    "                      \"kershape\":(192, 384, 1, 1, 1),\n",
    "                      \"outshape\":(1, 192, 16, 16, 16),\n",
    "                      \"stride\":(1, 1, 1),\n",
    "                      \"padding\":(0, 0, 0),\n",
    "                      \"dilation\":1,\n",
    "                       \"groups\":1,\n",
    "                       \"bias\": None\n",
    "                      },        \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_args(log_name, func, para, env='cuda'):\n",
    "    with autotvm.apply_history_best(log_name):\n",
    "        with tvm.target.create(env):\n",
    "            s, arg_bufs = func(*para)\n",
    "            print(arg_bufs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_correct(fw_log, bwd_inp_g_log, bwd_wei_g_log, inshape, kershape, outshape, stride, padding, dilation, groups, bias, schedule_direct_3d_cuda, schedule_conv3d_transpose_nchw_cuda, schedule_conv3d_nchw_cuda):\n",
    "    inp = get_rand(inshape)\n",
    "    wei = get_rand(kershape)\n",
    "    out = get_zero(outshape)\n",
    "    inp_grad = get_zero(inshape)\n",
    "    output_padding = _grad_input_padding(outshape, inshape, stride, padding, kershape[2:])   \n",
    "\n",
    "    #fw\n",
    "    fw_func = the_best_config_model(fw_log, schedule_direct_3d_cuda,(inshape, kershape, stride, padding, dilation))     \n",
    "    fw_func(inp, wei, out)\n",
    "\n",
    "\n",
    "    #bwd inp grad\n",
    "    bw_inp_func = the_best_config_model(bwd_inp_g_log, schedule_conv3d_transpose_nchw_cuda, (outshape, kershape, stride, padding, output_padding, 'float32') )        \n",
    "    bw_inp_func(out, wei, inp_grad)\n",
    "\n",
    "    #bwd wei grad\n",
    "    inp_rshape = reshape_inp_weight_shape(inshape)\n",
    "    grad_rshape = reshape_inp_weight_shape(outshape)\n",
    "\n",
    "    bw_wei_func = the_best_config_model(bwd_wei_g_log, schedule_conv3d_nchw_cuda,(inp_rshape, grad_rshape, dilation, padding, stride, groups) )        \n",
    "\n",
    "    inp_r = get_rand(inp_rshape)\n",
    "    grad_r = get_rand(grad_rshape)\n",
    "\n",
    "    kz = conv3d_ZHW_size(inp_rshape[2], dilation, padding[0], grad_rshape[2],stride[0])\n",
    "    kh = conv3d_ZHW_size(inp_rshape[3], dilation, padding[1], grad_rshape[3],stride[1])\n",
    "    kw = conv3d_ZHW_size(inp_rshape[4], dilation, padding[2], grad_rshape[4],stride[2])\n",
    "    wei_r = get_rand((kershape[1],kershape[0],kz,kh,kw))\n",
    "    bw_wei_func(inp_r,grad_r,wei_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(infile):\n",
    "    dispatch_context = autotvm.apply_history_best(infile)\n",
    "    targetkey = dispatch_context.best_by_targetkey\n",
    "    for a,i in targetkey.items():\n",
    "        break\n",
    "    index = i[0].config.index\n",
    "    return index\n",
    "\n",
    "def write2best_log(infile):\n",
    "    index = get_index(infile)\n",
    "    fo = open(infile, \"rb\")\n",
    "    foo = open(\"best.log\",\"a\")\n",
    "    for line in fo.readlines():\n",
    "        l = line.decode()\n",
    "        if l.find(str(index)) != -1:\n",
    "            foo.writelines(str(line.decode()))\n",
    "    fo.close()\n",
    "    foo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def autotuning_conv3d(data_dict, measure_option, n_trial, autotune_range = \"all\"):\n",
    "    for k,val in data_dict.items():\n",
    "        if (autotune_range != 'all' and (k not in autotune_range)):\n",
    "            continue\n",
    "        \n",
    "        print(\"Autotuning the \",k,\" layer\")\n",
    "        \n",
    "        #return keys\n",
    "        inshape, kershape, outshape, stride, padding, dilation, groups, bias = val.values()\n",
    "        \n",
    "        #get three log for one layer\n",
    "        fw_log, bwd_inp_g_log, bwd_wei_g_log = return_log_name(val.values())\n",
    "\n",
    "        #forward\n",
    "        auto_tune(schedule_direct_3d_cuda, (inshape, kershape, stride, padding, dilation), fw_log, n_trial, measure_option)\n",
    "\n",
    "        #input grad\n",
    "        output_padding = _grad_input_padding(outshape, inshape, stride, padding, kershape[2:])\n",
    "        auto_tune(schedule_conv3d_transpose_nchw_cuda, (outshape, kershape, stride, padding, output_padding, 'float32'), bwd_inp_g_log,  n_trial, measure_option)\n",
    "\n",
    "        #weight grad\n",
    "        inp_rshape = reshape_inp_weight_shape(inshape)\n",
    "        grad_rshape = reshape_inp_weight_shape(outshape)\n",
    "        auto_tune(schedule_conv3d_nchw_cuda, (inp_rshape, grad_rshape, dilation, padding, stride, groups), bwd_wei_g_log,  n_trial, measure_option)\n",
    "        \n",
    "        #testing\n",
    "        test_correct(fw_log, bwd_inp_g_log, bwd_wei_g_log, \\\n",
    "                     inshape, kershape, outshape, stride, padding, dilation, groups, bias, \\\n",
    "                     schedule_direct_3d_cuda, schedule_conv3d_transpose_nchw_cuda, schedule_conv3d_nchw_cuda)\n",
    "        \n",
    "        #write best config to best.log\n",
    "        write2best_log(fw_log)\n",
    "        write2best_log(bwd_inp_g_log)\n",
    "        write2best_log(bwd_wei_g_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trial = 800\n",
    "measure_option = autotvm.measure_option(\n",
    "        builder = autotvm.LocalBuilder(),\n",
    "        runner = autotvm.LocalRunner(repeat = 2, timeout = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotuning_conv3d(data_dict, measure_option, n_trial, autotune_range = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Autotuning the  0  layer\n",
    " Current/Best: 2415.93/2582.34 GFLOPS | Progress: (800/800) | 2953.19 s Done.\n",
    " Current/Best:  155.52/ 218.30 GFLOPS | Progress: (800/800) | 2433.96 s Done.\n",
    " Current/Best:   86.82/ 178.83 GFLOPS | Progress: (800/800) | 3117.65 s Done.\n",
    "Autotuning the  1  layer\n",
    " Current/Best: 1421.88/1509.51 GFLOPS | Progress: (800/800) | 2550.92 s Done.\n",
    " Current/Best: 2952.57/2994.98 GFLOPS | Progress: (800/800) | 3023.75 s Done.\n",
    " Current/Best:   36.76/  44.35 GFLOPS | Progress: (800/800) | 2674.58 s Done.\n",
    "Autotuning the  2  layer\n",
    " Current/Best: 1602.93/1655.66 GFLOPS | Progress: (800/800) | 3044.40 s Done.\n",
    " Current/Best: 4261.29/4361.13 GFLOPS | Progress: (800/800) | 2765.42 s Done.\n",
    " Current/Best:   39.25/  60.49 GFLOPS | Progress: (800/800) | 2656.35 s Done.\n",
    "Autotuning the  3  layer\n",
    " Current/Best: 5707.64/5811.98 GFLOPS | Progress: (800/800) | 3313.88 s Done.\n",
    " Current/Best: 6711.03/7495.22 GFLOPS | Progress: (800/800) | 3412.51 s Done.\n",
    " Current/Best:  951.74/1479.39 GFLOPS | Progress: (800/800) | 3568.30 s Done.\n",
    "Autotuning the  4  layer\n",
    " Current/Best: 2679.93/7148.30 GFLOPS | Progress: (800/800) | 3189.32 s Done.\n",
    " Current/Best: 6958.82/7565.79 GFLOPS | Progress: (800/800) | 3287.95 s Done.\n",
    " Current/Best: 1232.42/3567.63 GFLOPS | Progress: (800/800) | 3048.67 s Done.\n",
    "Autotuning the  5  layer\n",
    " Current/Best: 5739.71/7246.40 GFLOPS | Progress: (800/800) | 3337.61 s Done.\n",
    " Current/Best: 3460.18/5630.15 GFLOPS | Progress: (800/800) | 3105.91 s Done.\n",
    " Current/Best: 5797.22/7418.22 GFLOPS | Progress: (756/800) | 3169.93 s\n",
    "Autotuning the  6  layer\n",
    " Current/Best: 2054.31/4404.14 GFLOPS | Progress: (800/800) | 3194.88 s Done.\n",
    " Current/Best: 3057.28/3420.56 GFLOPS | Progress: (800/800) | 3459.32 s Done.\n",
    " Current/Best: 3021.82/5116.12 GFLOPS | Progress: (756/800) | 3131.69 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
